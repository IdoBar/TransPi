/*
================================================================================================
                                    Config File TransPi
================================================================================================
                            Transcriptome Analysis Pipeline
                            Author: Ramón E. Rivera-Vicéns
                            GitHub: rivera10
----------------------------------------------------------------------------------------
// nextflow.enable.dsl=1
*/
params {

    // -------------------------  EDIT below variables (mandatory)  ------------------------- //
    // --------------------- Can also be specified in the command line ---------------------- //

        // Modify this accordingly (if needed)
        // kmers list (depends on read length!)
            k=""

        // SOAP config file generator
            //#maximal read length
                maxReadLen=""
            //[LIB]
            //#maximal read length in this lib
                rd_len_cutof="${params.maxReadLen}"

            // Other options if needed. Leave defaults if unsure.
            //#average insert size
            //avg_ins="200"
            //#if sequence needs to be reversed
                reverse_seq="0"
            //#in which part(s) the reads are used
                asm_flags="3"
            //#minimum aligned length to contigs for a reliable read location (at least 32 for short insert size)
                map_len="32"

    // --------------------------  EDIT below variables if needed  -------------------------- //

    // Directory for results
        outdir="results"

    // Directory for trace files
        tracedir="pipeline_info"

    // PATH for rnammer, tmhmm, signalp programs. Requires licenses. See CBS-DTU tools for information.
        // RNAmmer
            rnam = "/home/ibar/scratch/tools/rnammer-1.2/rnammer"
        // Tmhmm
            tmhmm = "/home/ibar/scratch/tools/tmhmm-2.0c/bin/tmhmm"
        // SignalP
            signalp = "/home/ibar/scratch/tools/signalp-4.1/signalp"

    /*
    // ------------------------------------------------     STOP     ------------------------------------------------ //

        Most of these values below are filled by the precheck script (e.g. PATH to databases or conda installation).
        However, if you run the precheck for a container you will not have all these PATHs assigned (e.g. conda PATH).
        Run the precehck again but selecting conda instead of containers if that is the case.


        For other options (e.g. filtering, buscoDist, etc.) is recommended to call them from the command line.


        Proceed to the end of this config file to modify the processes CPUs and RAM with the specs of your system.
        Also to modify the profiles if you use a scheduler manager like SLURM or PBS.


        More info at the TransPi repository (https://github.com/PalMuc/TransPi) and
        manual (https://palmuc.github.io/TransPi/).


    // -------------------------------------------------------------------------------------------------------------- //
    */

    // PATH to TransPi DBs installation
        pipeInstall="/scratch/project/adna/tools/TransPi"

    // Uniprot database PATH
        uniprot="${params.pipeInstall}/DBs/uniprot_db/uniprot_sprot.pep"
        uniname="uniprot_sprot"

    //BUSCO database
        busco4db="${params.pipeInstall}/DBs/busco_db/mollusca_odb10"

    //PFAM file location
        pfloc="${params.pipeInstall}/DBs/hmmerdb/Pfam-A.hmm"

    //name of pfam file
        pfname="Pfam-A.hmm"

    //Trinotate sqlite created when installing Trinotate
        Tsql="${params.pipeInstall}/DBs/sqlite_db/*.sqlite"

    // Directory for reads
        reads=""

    // Pipeline options
        help = false
        fullHelp = false

    // Full analysis
        all = false

    // Only Evidential Gene run (one sample per run)
        onlyEvi = false

    // Only annotation analysis
        onlyAnn = false

    // Only Assemblies and Evidential Gene
        onlyAsm = false

    // Skip quality control
        skipQC = false

    // Skip fastp quality filter step
        skipFilter = false
    // Minimum reads quality for filtering in fastp
        minQual="15"

    // Filter rRNA
        rRNAfilter = true
        // rRNA database
        rRNAdb = "${params.pipeInstall}/DBs/rrna_db/SILVA_138.1_Small_and_Large_SURef_NR99_tax_silva_trunc.fasta"

    // Skip normalization of reads
        skipNormalization = false
        // Normalization parameters
        normMaxCov=100
        normMinCov=1

    // Save reads from filtering and normalization
        saveReads = false

    // Save bam file from mapping step
        saveBam = false

    // Filter Species using psytrans
        filterSpecies = false
    // Psytrans value to train model
        psyval=160
    // Host Sequence
        host=""
    // Symbiont Sequence
        symbiont=""

    // Run BUSCO in all assemblies
        allBuscos = false

    // BUSCO distribution analysis (this option needs to be run together with the allBuscos option)
        // Generate the analysis
        buscoDist = false
        // Mininmum percentage of assemblers require to rescue a BUSCO sequence
        minPerc="0.7"

    //short Transdecoder, no homlogy search (PFAM and UniProt)
        shortTransdecoder = false
    //Transdecoder genetic code
        genCode="Universal"

    // Annotation options
    // SignalP
        withSignalP = true
    // tmHMM
        withTMHMM = true
    // rnammer
        withRnammer = true
    // Add annotation to file
        addAnnotation = true

    //Test data
        readsTest = false

    // Skip Evidential Gene for onlyAsm option
        skipEvi = false

    // Kegg pathway search
        withKegg = false

    // Skip Report
        skipReport = false

    // These options will change how the profiles work.
        // Run with conda installed by the precheck
            //next 2 parameters are outdated
                myConda = false
                myCondaInstall=""

            condaActivate = false

        // TransPi container with all programs
            oneContainer = false

        // Cache directory for conda and singularity files. Leave in blank if not sure
            envCacheDir = "$NXF_SINGULARITY_CACHEDIR"

        // Singularity
        // Use singularity image created after pulling from docker and not from Galaxy depot (singularity image ready to use).
            singularity_pull_docker_container = false

    // Get software versions - only works with local conda installation and TransPi container.
        skipGetRunInfo = false
}

/*
// ------------------------------------------------     NOTE     ------------------------------------------------ //


    Proceed to modify the processes CPUs and RAM with the specs of your system.
    Also to modify the profiles if you use a scheduler manager like SLURM or PBS.


    More info at the TransPi repository (https://github.com/PalMuc/TransPi) and
    manual (https://palmuc.github.io/TransPi/).

    Also see Nextflow documentation (https://www.nextflow.io/docs/latest/index.html).


// -------------------------------------------------------------------------------------------------------------- //
*/

process {
    cpus=1
    memory=5.GB
    withLabel: big_cpus {
        cpus = { check_max( 48, 'cpus' ) }
        memory = { check_max( 64.GB + (8.GB * task.attempt), 'memory' ) }
        time = { check_max( 20.h + (task.attempt * 8.h), 'time' ) }
        // queue = { task.memory < 48.GB ? 'workq' : (task.memory < 96.GB ? 'bigmem' : 'longbigmem') } 

    }
    withLabel: med_cpus {
	cpus = { check_max( 16, 'cpus' ) }
        memory = { check_max( 40.GB + (8.GB * task.attempt), 'memory' ) }
        time = { check_max( 16.h + (task.attempt * 4.h), 'time' ) }
    }
    withLabel: low_cpus {
	cpus = { check_max( 4, 'cpus' ) }
        memory = { check_max( 26.GB + (6.GB * task.attempt), 'memory' ) }
        time = { check_max( 6.h + (task.attempt * 2.h), 'time' ) }
    }
    withLabel: exlow_cpus {
	cpus = { check_max( 1, 'cpus' ) }
        memory = { check_max( 6.GB + (4.GB * task.attempt), 'memory' ) }
        time = { check_max( 4.h + (task.attempt * 2.h), 'time' ) }
    }
    withLabel: big_mem {
	    // clusterOptions = '-q longbigmem'
	cpus = { check_max( 32, 'cpus' ) }
        memory = { check_max( 80.GB + (16.GB * task.attempt), 'memory' ) }
        time = { check_max( 24.h + (task.attempt * 6.h), 'time' ) }
        // queue = { task.memory < 48.GB ? 'workq' : (task.memory < 96.GB ? 'bigmem' : 'longbigmem') } 
    }
    withLabel: med_mem {
	    // clusterOptions = '-q bigmem'
	cpus = { check_max( 16, 'cpus' ) }
        memory = { check_max( 32.GB + (16.GB * task.attempt), 'memory' ) }
        time = { check_max( 16.h + (task.attempt * 4.h), 'time' ) }
        // queue = { task.memory < 48.GB ? 'workq' : (task.memory < 96.GB ? 'bigmem' : 'longbigmem') } 
    }
    withLabel: low_mem {
	cpus = { check_max( 8, 'cpus' ) }
        memory = { check_max( 24.GB + (8.GB * task.attempt), 'memory' ) }
        time = { check_max( 12.h + (task.attempt * 2.h), 'time' ) }
    }
    withName: '.*hmmer.*' {
        time = { check_max( 16.h + (task.attempt * 4.h), 'time' ) }
    }
    withName: get_GO_comparison {
        time = { check_max( 4.h + (task.attempt * 2.h), 'time' ) }
    }
    withName: 'fast.+' {
        time = { check_max( 2.h + (task.attempt * 1.h), 'time' ) }
    }
    withName: '.+_assembly' {
	memory = { check_max( 80.GB + (16.GB * task.attempt), 'memory' ) }
	time = { check_max( 40.h + (task.attempt * 20.h), 'time' ) }
    }
    withName: 'evigene' {
        memory = { check_max(60.GB + (12.GB * task.attempt), 'memory' ) }
        time = { check_max( 10.h + (task.attempt * 2.h), 'time' ) }
    }
    withName: 'rna_quast' {
        apptainer.envWhitelist=['PATH']
        
    }



//    withName: 'trinity_assembly|velvet_oases_assembly' {
  //      scratch = false
//    }

    

//    errorStrategy='finish'
    errorStrategy = { task.exitStatus in [143,137,104,134,139,140,125,255,''] ? 'retry' : 'finish' }
    maxRetries = 2
    maxErrors = '-1'   
}

// env Evidential Gene variable (only for nextflow)
env.evi="${projectDir}/scripts/evigene"

// Get PATH for cache environments
params.localCacheDir = (params.envCacheDir ? "${params.envCacheDir}" : "${launchDir}")

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-eo', 'pipefail']

profiles {
    conda {
        params.condaActivate = true
        params.localConda="${params.myCondaInstall}"
        // cache for condaEnv created individually
        conda.cacheDir = "${params.localCacheDir}/condaEnv/"
    }
    docker {
        docker.enabled = true
        docker.runOptions = "-u \$(id -u):\$(id -g) -v ${params.pipeInstall="$HOME/tools/TransPi"}:${params.pipeInstall}"
        // --mount type=bind,src=${params.pipeInstall="$HOME/tools/TransPi"},dst=/dockerDB"
    }
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        // cache for images from docker pull
        singularity.cacheDir="$NXF_SINGULARITY_CACHEDIR"
//        singularity.runOptions="-B ${params.pipeInstall}/bin"
	process {
        //    container = "file://${params.pipeInstall}/transpi_v1.0.0.sif"
        }	
    }
    test {
        includeConfig "conf/test.config"
        readsTest = [
        ['Sponge_sample', ['https://github.com/rivera10/test_dataset/raw/master/RNA_data/Tethya_wilhelma_R1.fastq.gz'], ['https://github.com/rivera10/test_dataset/raw/master/RNA_data/Tethya_wilhelma_R2.fastq.gz']]
    ]
        k="25,53"
        maxReadLen=100
        shortTransdecoder = true
    }
    TransPiContainer {
        process {
            params.oneContainer = true
            params.TPcontainer="file:///$NXF_SINGULARITY_CACHEDIR/transpi/transpi_v1.0.0.sif"
	    params.v4container="file:///$NXF_SINGULARITY_CACHEDIR/transpi/busco_v4.1.4_cv1.sif"
	    params.diamondcontainer="file:///$NXF_SINGULARITY_CACHEDIR/transpi/diamond_latest.sif"
	  //  params.TPcontainer="file://transpi_v1.0.0.sif"
	  //  params.TPcontainer="rerv/transpi:v1.0.0"
        }
    }
    palmuc {
        process {
            executor='slurm'
            clusterOptions='-p lemmium --qos=low'
        }
    }
}
/*
executor {
  $slurm {
    queueSize=100
  }
}
*/
timeline {
  enabled = true
  overwrite = true
  file = "${params.outdir}/${params.tracedir}/transpi_timeline.html"
}
report {
  enabled = true
  overwrite = true
  file = "${params.outdir}/${params.tracedir}/transpi_report.html"
}
trace {
  enabled = true
  overwrite = true
  file = "${params.outdir}/${params.tracedir}/transpi_trace.txt"
}
dag {
  enabled = true
  overwrite = true
  file = "${params.outdir}/${params.tracedir}/transpi_dag.html"
}

manifest {
    name = 'TransPi'
    author = 'Ramón E. Rivera-Vicéns'
    description = 'Transcriptome Analysis Pipeline'
    mainScript = 'TransPi.nf'
    nextflowVersion = '>=21.04.1'
    version = '1.3.0-rc'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit (only needed while using this config file locally)
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

